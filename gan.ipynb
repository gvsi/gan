{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from json_tricks import dumps, loads\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "lines = []\n",
    "with open(\"data/data4/fl4-comb.txt\") as f:\n",
    "    for line in f:\n",
    "        lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3828/3828 [00:01<00:00, 3201.16it/s]\n"
     ]
    }
   ],
   "source": [
    "Qs = []\n",
    "for i in tqdm(range(len(lines))):\n",
    "    map_str_comb, dic = lines[i].split(\"\\t\")\n",
    "    obj = loads(dic)\n",
    "    Qs.append(obj['Q'])\n",
    "#     print(map_str_comb)\n",
    "#     print(obj['Q'])\n",
    "#     print(obj['start'])\n",
    "#     print(obj['end'])\n",
    "#     print(obj['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.array([list(q.flatten()) for q in Qs]))\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12195581, 0.08256955, 0.08251324, 0.12372228],\n",
       "       [0.0821906 , 0.05761942, 0.05719702, 0.09444015],\n",
       "       [0.07815579, 0.0540326 , 0.06380972, 0.07943222],\n",
       "       [0.08916016, 0.08788628, 0.11889415, 0.08951577],\n",
       "       [0.09738987, 0.05795529, 0.05877805, 0.08288135],\n",
       "       [0.05276304, 0.05120913, 0.05172947, 0.05426049],\n",
       "       [0.07073826, 0.08033005, 0.07113202, 0.06475014],\n",
       "       [0.11527473, 0.18617917, 0.17126957, 0.11207997],\n",
       "       [0.08072407, 0.06367607, 0.05345485, 0.07876516],\n",
       "       [0.06687505, 0.07218775, 0.08300659, 0.07017861],\n",
       "       [0.12329497, 0.15297471, 0.15264606, 0.12188077],\n",
       "       [0.23387151, 0.39187228, 0.36675139, 0.22995599],\n",
       "       [0.09059788, 0.11839352, 0.0876327 , 0.088986  ],\n",
       "       [0.10975108, 0.1710683 , 0.18492716, 0.11169723],\n",
       "       [0.2356622 , 0.35998902, 0.39185281, 0.22972349],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data.describe().loc['mean']).reshape((16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a3389b4a8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1829e2c4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(np.array(data.describe().loc['mean']).reshape((16,4)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_data = np.array([q.flatten() for q in Qs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(q_data, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size = 32\n",
    "Z_dim = 100\n",
    "X_dim = X_train.shape[1]\n",
    "# X_dim = mnist.train.images.shape[1]\n",
    "h_dim = 40\n",
    "c = 0\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return Variable(torch.randn(*size) * xavier_stddev, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ==================== GENERATOR ======================== \"\"\"\n",
    "\n",
    "Wzh = xavier_init(size=[Z_dim, h_dim])\n",
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whx = xavier_init(size=[h_dim, X_dim])\n",
    "bhx = Variable(torch.zeros(X_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def G(z):\n",
    "    h = nn.relu(z @ Wzh + bzh.repeat(z.size(0), 1))\n",
    "    X = nn.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ==================== DISCRIMINATOR ======================== \"\"\"\n",
    "\n",
    "Wxh = xavier_init(size=[X_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Why = xavier_init(size=[h_dim, 1])\n",
    "bhy = Variable(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "\n",
    "def D(X):\n",
    "    h = nn.relu(X @ Wxh + bxh.repeat(X.size(0), 1))\n",
    "    y = nn.sigmoid(h @ Why + bhy.repeat(h.size(0), 1))\n",
    "    return y\n",
    "\n",
    "\n",
    "G_params = [Wzh, bzh, Whx, bhx]\n",
    "D_params = [Wxh, bxh, Why, bhy]\n",
    "params = G_params + D_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ===================== TRAINING ======================== \"\"\"\n",
    "\n",
    "def reset_grad():\n",
    "    for p in params:\n",
    "        if p.grad is not None:\n",
    "            data = p.grad.data\n",
    "            p.grad = Variable(data.new().resize_as_(data).zero_())\n",
    "\n",
    "G_solver = optim.Adam(G_params, lr=1e-3)\n",
    "D_solver = optim.Adam(D_params, lr=1e-3)\n",
    "\n",
    "ones_label = Variable(torch.ones(mb_size))\n",
    "zeros_label = Variable(torch.zeros(mb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    return data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gvsi/anaconda3/envs/gan/lib/python3.6/site-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; D_loss: [1.5710366]; G_loss: [0.52704453]\n",
      "Iter-1000; D_loss: [1.2924922]; G_loss: [0.77230173]\n",
      "Iter-2000; D_loss: [1.2746984]; G_loss: [0.8115677]\n",
      "Iter-3000; D_loss: [1.2224678]; G_loss: [0.77875286]\n",
      "Iter-4000; D_loss: [1.4340537]; G_loss: [0.78227544]\n",
      "Iter-5000; D_loss: [1.3934699]; G_loss: [0.93907857]\n",
      "Iter-6000; D_loss: [1.2604795]; G_loss: [0.908802]\n",
      "Iter-7000; D_loss: [1.1772506]; G_loss: [1.1064316]\n",
      "Iter-8000; D_loss: [1.1307936]; G_loss: [0.89670444]\n",
      "Iter-9000; D_loss: [1.2526524]; G_loss: [0.9836535]\n",
      "Iter-10000; D_loss: [1.2759435]; G_loss: [0.80982125]\n",
      "Iter-11000; D_loss: [1.1886551]; G_loss: [0.9661324]\n",
      "Iter-12000; D_loss: [1.072839]; G_loss: [0.80148476]\n",
      "Iter-13000; D_loss: [1.1911745]; G_loss: [0.8232041]\n",
      "Iter-14000; D_loss: [1.383947]; G_loss: [0.7831403]\n",
      "Iter-15000; D_loss: [1.3972119]; G_loss: [0.7602152]\n",
      "Iter-16000; D_loss: [1.2598553]; G_loss: [0.83323]\n",
      "Iter-17000; D_loss: [1.4081066]; G_loss: [0.7366711]\n",
      "Iter-18000; D_loss: [1.3211932]; G_loss: [0.77463526]\n",
      "Iter-19000; D_loss: [1.229676]; G_loss: [0.7576648]\n",
      "Iter-20000; D_loss: [1.3517742]; G_loss: [0.84646624]\n",
      "Iter-21000; D_loss: [1.2449453]; G_loss: [0.7701815]\n",
      "Iter-22000; D_loss: [1.4038332]; G_loss: [0.78798884]\n",
      "Iter-23000; D_loss: [1.4297609]; G_loss: [0.7761401]\n",
      "Iter-24000; D_loss: [1.3559072]; G_loss: [0.7295369]\n",
      "Iter-25000; D_loss: [1.2765429]; G_loss: [0.7698473]\n",
      "Iter-26000; D_loss: [1.3900318]; G_loss: [0.7918084]\n",
      "Iter-27000; D_loss: [1.3880002]; G_loss: [0.8127853]\n",
      "Iter-28000; D_loss: [1.3397435]; G_loss: [0.80235577]\n",
      "Iter-29000; D_loss: [1.3586078]; G_loss: [0.8410171]\n",
      "Iter-30000; D_loss: [1.3131251]; G_loss: [0.85678405]\n",
      "Iter-31000; D_loss: [1.3334546]; G_loss: [0.92924935]\n",
      "Iter-32000; D_loss: [1.337409]; G_loss: [0.78018695]\n",
      "Iter-33000; D_loss: [1.3777415]; G_loss: [0.7679703]\n",
      "Iter-34000; D_loss: [1.1697714]; G_loss: [0.76746315]\n",
      "Iter-35000; D_loss: [1.3286195]; G_loss: [0.8125595]\n",
      "Iter-36000; D_loss: [1.3054159]; G_loss: [0.88363504]\n",
      "Iter-37000; D_loss: [1.3522029]; G_loss: [0.7595018]\n",
      "Iter-38000; D_loss: [1.3188517]; G_loss: [0.86340225]\n",
      "Iter-39000; D_loss: [1.3773143]; G_loss: [0.7992246]\n",
      "Iter-40000; D_loss: [1.1393676]; G_loss: [1.0071514]\n",
      "Iter-41000; D_loss: [1.4131072]; G_loss: [0.7998937]\n",
      "Iter-42000; D_loss: [1.3041008]; G_loss: [0.7927968]\n",
      "Iter-43000; D_loss: [1.2178807]; G_loss: [0.86438197]\n",
      "Iter-44000; D_loss: [1.2061212]; G_loss: [0.8359817]\n",
      "Iter-45000; D_loss: [1.2935095]; G_loss: [0.8347272]\n",
      "Iter-46000; D_loss: [1.1870992]; G_loss: [0.8189447]\n",
      "Iter-47000; D_loss: [1.312967]; G_loss: [0.80766094]\n",
      "Iter-48000; D_loss: [1.2469803]; G_loss: [0.8315899]\n",
      "Iter-49000; D_loss: [1.2981378]; G_loss: [0.80670524]\n",
      "Iter-50000; D_loss: [1.2659285]; G_loss: [0.7376076]\n",
      "Iter-51000; D_loss: [1.2803483]; G_loss: [0.8132596]\n",
      "Iter-52000; D_loss: [1.2083615]; G_loss: [0.7108325]\n",
      "Iter-53000; D_loss: [1.3065108]; G_loss: [0.8241182]\n",
      "Iter-54000; D_loss: [1.3486888]; G_loss: [0.85674256]\n",
      "Iter-55000; D_loss: [1.3227463]; G_loss: [1.0159999]\n",
      "Iter-56000; D_loss: [1.3477075]; G_loss: [0.8937729]\n",
      "Iter-57000; D_loss: [1.2991168]; G_loss: [0.8718134]\n",
      "Iter-58000; D_loss: [1.3020151]; G_loss: [0.9688307]\n",
      "Iter-59000; D_loss: [1.2869525]; G_loss: [0.838012]\n",
      "Iter-60000; D_loss: [1.1969872]; G_loss: [1.0725193]\n",
      "Iter-61000; D_loss: [1.1729524]; G_loss: [0.9055539]\n",
      "Iter-62000; D_loss: [1.244765]; G_loss: [0.7904599]\n",
      "Iter-63000; D_loss: [1.3127868]; G_loss: [0.83109397]\n",
      "Iter-64000; D_loss: [1.2342376]; G_loss: [0.93018866]\n",
      "Iter-65000; D_loss: [1.2129506]; G_loss: [0.870807]\n",
      "Iter-66000; D_loss: [1.1622858]; G_loss: [0.7909794]\n",
      "Iter-67000; D_loss: [1.1449845]; G_loss: [0.82819474]\n",
      "Iter-68000; D_loss: [1.0604725]; G_loss: [0.885459]\n",
      "Iter-69000; D_loss: [1.3191028]; G_loss: [0.88013685]\n",
      "Iter-70000; D_loss: [1.2202592]; G_loss: [0.7732512]\n",
      "Iter-71000; D_loss: [1.2672622]; G_loss: [0.9776209]\n",
      "Iter-72000; D_loss: [1.148747]; G_loss: [0.9022211]\n",
      "Iter-73000; D_loss: [1.307824]; G_loss: [0.8118329]\n",
      "Iter-74000; D_loss: [1.2604606]; G_loss: [0.87920165]\n",
      "Iter-75000; D_loss: [1.173634]; G_loss: [0.81125206]\n",
      "Iter-76000; D_loss: [1.1631579]; G_loss: [0.7990107]\n",
      "Iter-77000; D_loss: [1.2415885]; G_loss: [0.97898567]\n",
      "Iter-78000; D_loss: [1.1746914]; G_loss: [0.98320675]\n",
      "Iter-79000; D_loss: [1.2089455]; G_loss: [0.9080064]\n",
      "Iter-80000; D_loss: [1.2745779]; G_loss: [0.8022543]\n",
      "Iter-81000; D_loss: [1.1662184]; G_loss: [0.83034843]\n",
      "Iter-82000; D_loss: [1.2337582]; G_loss: [0.95718414]\n",
      "Iter-83000; D_loss: [1.1641126]; G_loss: [0.86596406]\n",
      "Iter-84000; D_loss: [1.3353857]; G_loss: [0.83976465]\n",
      "Iter-85000; D_loss: [1.0517972]; G_loss: [1.0762216]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for it in range(100000):\n",
    "    # Sample data\n",
    "    z = Variable(torch.randn(mb_size, Z_dim))\n",
    "#     X, _ = mnist.train.next_batch(mb_size)\n",
    "    X = next_batch(mb_size, X_train)\n",
    "    X = Variable(torch.from_numpy(X).float())\n",
    "\n",
    "    # Dicriminator forward-loss-backward-update\n",
    "    G_sample = G(z)\n",
    "    D_real = D(X)\n",
    "    D_fake = D(G_sample)\n",
    "\n",
    "    D_loss_real = nn.binary_cross_entropy(D_real, ones_label)\n",
    "    D_loss_fake = nn.binary_cross_entropy(D_fake, zeros_label)\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "    D_loss.backward()\n",
    "    D_solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Generator forward-loss-backward-update\n",
    "    z = Variable(torch.randn(mb_size, Z_dim))\n",
    "    G_sample = G(z)\n",
    "    D_fake = D(G_sample)\n",
    "\n",
    "    G_loss = nn.binary_cross_entropy(D_fake, ones_label)\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, D_loss.data.numpy(), G_loss.data.numpy()))\n",
    "\n",
    "        samples = G(z).data.numpy()[:16]\n",
    "\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        gs = gridspec.GridSpec(4, 4)\n",
    "        gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(sample.reshape(16, 4), cmap='Greys_r')\n",
    "\n",
    "        if not os.path.exists('out/'):\n",
    "            os.makedirs('out/')\n",
    "\n",
    "        plt.savefig('out/{}.png'.format(str(c).zfill(3)), bbox_inches='tight')\n",
    "        c += 1\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Variable(torch.from_numpy(X_test[:32]).float(), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15333582, 0.0329516 , 0.12457457, 0.1492146 ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.30415007, 0.23366085, 0.14658506, 0.06507196],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.29920027, 0.01608911, 0.06598258, 0.19960965],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.45623335, 0.40752405, 0.5204927 , 0.3729392 ],\n",
       "       [0.00261711, 0.6146905 , 0.0233491 , 0.13710801],\n",
       "       [0.13392164, 0.7542627 , 0.15535785, 0.03055874],\n",
       "       [0.        , 0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].data.numpy().reshape((16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "myD = D(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.5614\n",
       " 0.5477\n",
       " 0.6021\n",
       " 0.5176\n",
       " 0.5552\n",
       " 0.3682\n",
       " 0.5286\n",
       " 0.4774\n",
       " 0.5683\n",
       " 0.3390\n",
       " 0.6488\n",
       " 0.6656\n",
       " 0.5875\n",
       " 0.5153\n",
       " 0.5002\n",
       " 0.6334\n",
       " 0.5796\n",
       " 0.5564\n",
       " 0.4498\n",
       " 0.7221\n",
       " 0.7104\n",
       " 0.6548\n",
       " 0.3286\n",
       " 0.5662\n",
       " 0.5241\n",
       " 0.5212\n",
       " 0.4746\n",
       " 0.4181\n",
       " 0.4664\n",
       " 0.6021\n",
       " 0.5226\n",
       " 0.5492\n",
       "[torch.FloatTensor of size 32x1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "myD.backward(ones_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07476655, -0.05764935,  0.16091815, -0.04483762],\n",
       "       [-0.22876197, -0.0927763 , -0.09430572, -0.01484902],\n",
       "       [-0.08592287, -0.13225855, -0.13456981, -0.2535544 ],\n",
       "       [-0.15668412, -0.08589231, -0.14675155, -0.01480279],\n",
       "       [ 0.09340923, -0.08414229,  0.02626451, -0.02154179],\n",
       "       [ 0.0253772 , -0.20938489,  0.0446586 , -0.01366944],\n",
       "       [-0.36005983, -0.12268673,  0.00280628, -0.09902528],\n",
       "       [-0.17990404, -0.1315676 , -0.08670446, -0.27089626],\n",
       "       [-0.05931345,  0.0719294 ,  0.05885528, -0.03061749],\n",
       "       [-0.15295711,  0.02905678, -0.5305588 , -0.2659753 ],\n",
       "       [ 0.05728214,  0.03181767,  0.04154145, -0.03438391],\n",
       "       [-0.94014174, -0.87706536, -0.4661052 , -0.8666274 ],\n",
       "       [-0.12391417,  0.20117874, -0.07811835, -0.06466088],\n",
       "       [-0.08732299, -0.02977875, -0.0153512 ,  0.02155736],\n",
       "       [-0.08298463,  0.15773563,  0.06293063,  0.1042875 ],\n",
       "       [-1.418243  , -1.2299803 , -1.0473963 , -0.98857397]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.grad.data.numpy()[0].reshape((16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2 = inputs.data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15333582, 0.0329516 , 0.12457457, 0.1492146 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.30415007, 0.23366085, 0.14658506, 0.06507196,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.29920027, 0.01608911, 0.06598258,\n",
       "       0.19960965, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.45623335, 0.40752405,\n",
       "       0.5204927 , 0.3729392 , 0.00261711, 0.6146905 , 0.0233491 ,\n",
       "       0.13710801, 0.13392164, 0.7542627 , 0.15535785, 0.03055874,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a24dd9898>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a24bbb550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(inputs2.reshape((16,4)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       " 0.5614\n",
       "[torch.FloatTensor of size 64x1]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D(Variable(torch.from_numpy(inputs2.flatten()).float(), requires_grad=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gan)",
   "language": "python",
   "name": "gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
