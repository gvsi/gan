{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from json_tricks import dumps, loads\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "lines = []\n",
    "with open(\"data/data4_valid/fl4-comb-new.txt\") as f:\n",
    "    for line in f:\n",
    "        lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3828/3828 [00:20<00:00, 184.80it/s]\n"
     ]
    }
   ],
   "source": [
    "Qs = []\n",
    "for i in tqdm(range(len(lines))):\n",
    "    map_str_comb, dic = lines[i].split(\"\\t\")\n",
    "    obj = loads(dic)\n",
    "    Qs.append(obj['Q'])\n",
    "#     print(map_str_comb)\n",
    "#     print(obj['Q'])\n",
    "#     print(obj['start'])\n",
    "#     print(obj['end'])\n",
    "#     print(obj['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.array([list(q.flatten()) for q in Qs]))\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12605694, 0.0833256 , 0.08297108, 0.12353941],\n",
       "       [0.08128873, 0.05724625, 0.05659838, 0.09661872],\n",
       "       [0.08087064, 0.05331417, 0.06352362, 0.08263363],\n",
       "       [0.08988946, 0.08878639, 0.12008143, 0.09073982],\n",
       "       [0.09580999, 0.05698207, 0.05771588, 0.08112013],\n",
       "       [0.05099827, 0.05139299, 0.05043681, 0.05229824],\n",
       "       [0.07261287, 0.07937687, 0.07230626, 0.06553421],\n",
       "       [0.11599771, 0.18485035, 0.1737943 , 0.11099252],\n",
       "       [0.08197991, 0.06288321, 0.05389169, 0.07824682],\n",
       "       [0.06590338, 0.06913064, 0.07649124, 0.06986908],\n",
       "       [0.1207364 , 0.15513544, 0.14925819, 0.12778036],\n",
       "       [0.22836985, 0.39108632, 0.36243487, 0.22880617],\n",
       "       [0.09093449, 0.11885227, 0.09104228, 0.08888373],\n",
       "       [0.11384063, 0.17271849, 0.18458059, 0.1095291 ],\n",
       "       [0.23501638, 0.35944002, 0.38642703, 0.23150493],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data.describe().loc['mean']).reshape((16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12605694, 0.0833256 , 0.08297108, 0.12353941, 0.08128873,\n",
       "       0.05724625, 0.05659838, 0.09661872, 0.08087064, 0.05331417,\n",
       "       0.06352362, 0.08263363, 0.08988946, 0.08878639, 0.12008143,\n",
       "       0.09073982, 0.09580999, 0.05698207, 0.05771588, 0.08112013,\n",
       "       0.05099827, 0.05139299, 0.05043681, 0.05229824, 0.07261287,\n",
       "       0.07937687, 0.07230626, 0.06553421, 0.11599771, 0.18485035,\n",
       "       0.1737943 , 0.11099252, 0.08197991, 0.06288321, 0.05389169,\n",
       "       0.07824682, 0.06590338, 0.06913064, 0.07649124, 0.06986908,\n",
       "       0.1207364 , 0.15513544, 0.14925819, 0.12778036, 0.22836985,\n",
       "       0.39108632, 0.36243487, 0.22880617, 0.09093449, 0.11885227,\n",
       "       0.09104228, 0.08888373, 0.11384063, 0.17271849, 0.18458059,\n",
       "       0.1095291 , 0.23501638, 0.35944002, 0.38642703, 0.23150493,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data.describe().loc['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a1e389390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1de02f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(np.array(data.describe().loc['mean']).reshape((16,4)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_data = np.array([q.flatten() for q in Qs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(q_data, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.16377471e-03,  4.76247463e-03, -3.72915789e-04,  5.47921725e-02,\n",
       "        1.61420948e-02, -1.77593953e-03, -2.27810865e-03,  1.23271672e-02,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        6.93360790e-02,  8.70303075e-02,  4.14953570e-01,  3.60708108e-01,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.49819926e-03, -2.44130913e-03, -2.41167584e-03, -8.09420665e-04,\n",
       "       -1.53353350e-03,  9.93214391e-02,  6.80018972e-02,  7.46301022e-02,\n",
       "        3.68077790e-01,  7.58032172e-01,  3.69968455e-01,  3.54609095e-01,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.46718768e-03,  6.82141150e-01,  5.50165250e-02, -1.34924672e-03,\n",
       "        2.10026171e-01,  9.83456490e-02,  9.72448049e-01,  4.48880585e-01,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size = 32\n",
    "Z_dim = 100\n",
    "X_dim = X_train.shape[1]\n",
    "# X_dim = mnist.train.images.shape[1]\n",
    "h_dim = 40\n",
    "c = 0\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return Variable(torch.randn(*size) * xavier_stddev, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ==================== GENERATOR ======================== \"\"\"\n",
    "\n",
    "Wzh = xavier_init(size=[Z_dim, h_dim])\n",
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whx = xavier_init(size=[h_dim, X_dim])\n",
    "bhx = Variable(torch.zeros(X_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def G(z):\n",
    "    h = nn.relu(z @ Wzh + bzh.repeat(z.size(0), 1))\n",
    "    X = nn.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ==================== DISCRIMINATOR ======================== \"\"\"\n",
    "\n",
    "Wxh = xavier_init(size=[X_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Why = xavier_init(size=[h_dim, 1])\n",
    "bhy = Variable(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "\n",
    "def D(X):\n",
    "    h = nn.relu(X @ Wxh + bxh.repeat(X.size(0), 1))\n",
    "    y = nn.sigmoid(h @ Why + bhy.repeat(h.size(0), 1))\n",
    "    return y\n",
    "\n",
    "\n",
    "G_params = [Wzh, bzh, Whx, bhx]\n",
    "D_params = [Wxh, bxh, Why, bhy]\n",
    "params = G_params + D_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ===================== TRAINING ======================== \"\"\"\n",
    "\n",
    "def reset_grad():\n",
    "    for p in params:\n",
    "        if p.grad is not None:\n",
    "            data = p.grad.data\n",
    "            p.grad = Variable(data.new().resize_as_(data).zero_())\n",
    "\n",
    "G_solver = optim.Adam(G_params, lr=1e-3)\n",
    "D_solver = optim.Adam(D_params, lr=1e-3)\n",
    "\n",
    "ones_label = Variable(torch.ones(mb_size))\n",
    "zeros_label = Variable(torch.zeros(mb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    return data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gvsi/anaconda3/envs/gan/lib/python3.6/site-packages/torch/nn/functional.py:1168: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; D_loss: [1.0959744]; G_loss: [1.3927464]\n",
      "Iter-1000; D_loss: [1.1537104]; G_loss: [1.1945972]\n",
      "Iter-2000; D_loss: [1.0708642]; G_loss: [0.9161543]\n",
      "Iter-3000; D_loss: [1.1765244]; G_loss: [0.8007257]\n",
      "Iter-4000; D_loss: [1.1176058]; G_loss: [0.933995]\n",
      "Iter-5000; D_loss: [1.2397776]; G_loss: [0.92559123]\n",
      "Iter-6000; D_loss: [1.2252352]; G_loss: [0.7989011]\n",
      "Iter-7000; D_loss: [1.2462945]; G_loss: [1.0362389]\n",
      "Iter-8000; D_loss: [1.3048198]; G_loss: [0.70606285]\n",
      "Iter-9000; D_loss: [1.3573613]; G_loss: [0.8641703]\n",
      "Iter-10000; D_loss: [1.2790121]; G_loss: [0.785764]\n",
      "Iter-11000; D_loss: [1.214653]; G_loss: [0.89359033]\n",
      "Iter-12000; D_loss: [1.3786997]; G_loss: [0.8635296]\n",
      "Iter-13000; D_loss: [1.3282288]; G_loss: [0.8703219]\n",
      "Iter-14000; D_loss: [1.2864697]; G_loss: [0.79983693]\n",
      "Iter-15000; D_loss: [1.2704588]; G_loss: [0.89859056]\n",
      "Iter-16000; D_loss: [1.2395549]; G_loss: [0.8264526]\n",
      "Iter-17000; D_loss: [1.3191288]; G_loss: [0.84736335]\n",
      "Iter-18000; D_loss: [1.3775992]; G_loss: [0.9206655]\n",
      "Iter-19000; D_loss: [1.4240062]; G_loss: [0.74373573]\n",
      "Iter-20000; D_loss: [1.2595983]; G_loss: [0.8171325]\n",
      "Iter-21000; D_loss: [1.3553416]; G_loss: [0.852945]\n",
      "Iter-22000; D_loss: [1.3338196]; G_loss: [0.8044693]\n",
      "Iter-23000; D_loss: [1.3248276]; G_loss: [0.8179233]\n",
      "Iter-24000; D_loss: [1.3194251]; G_loss: [0.78213704]\n",
      "Iter-25000; D_loss: [1.3018384]; G_loss: [0.7258622]\n",
      "Iter-26000; D_loss: [1.3850391]; G_loss: [0.74555343]\n",
      "Iter-27000; D_loss: [1.3715913]; G_loss: [0.7873118]\n",
      "Iter-28000; D_loss: [1.3604134]; G_loss: [0.76438767]\n",
      "Iter-29000; D_loss: [1.2640479]; G_loss: [0.7624385]\n",
      "Iter-30000; D_loss: [1.2996168]; G_loss: [0.7639366]\n",
      "Iter-31000; D_loss: [1.2970607]; G_loss: [0.83639836]\n",
      "Iter-32000; D_loss: [1.4145253]; G_loss: [0.68344337]\n",
      "Iter-33000; D_loss: [1.2846481]; G_loss: [0.78414947]\n",
      "Iter-34000; D_loss: [1.2689102]; G_loss: [0.8146039]\n",
      "Iter-35000; D_loss: [1.3528633]; G_loss: [0.82539636]\n",
      "Iter-36000; D_loss: [1.2376132]; G_loss: [0.7876337]\n",
      "Iter-37000; D_loss: [1.3130085]; G_loss: [0.81481814]\n",
      "Iter-38000; D_loss: [1.3767835]; G_loss: [0.8256767]\n",
      "Iter-39000; D_loss: [1.2463026]; G_loss: [0.819793]\n",
      "Iter-40000; D_loss: [1.310678]; G_loss: [0.9230882]\n",
      "Iter-41000; D_loss: [1.3161566]; G_loss: [0.8393501]\n",
      "Iter-42000; D_loss: [1.254633]; G_loss: [0.8206036]\n",
      "Iter-43000; D_loss: [1.3097913]; G_loss: [0.8330662]\n",
      "Iter-44000; D_loss: [1.3145777]; G_loss: [0.7955752]\n",
      "Iter-45000; D_loss: [1.2003415]; G_loss: [0.8726002]\n",
      "Iter-46000; D_loss: [1.2910756]; G_loss: [0.8769329]\n",
      "Iter-47000; D_loss: [1.2948147]; G_loss: [0.86466455]\n",
      "Iter-48000; D_loss: [1.2850769]; G_loss: [0.7557627]\n",
      "Iter-49000; D_loss: [1.1794479]; G_loss: [0.9193895]\n",
      "Iter-50000; D_loss: [1.2580147]; G_loss: [0.772412]\n",
      "Iter-51000; D_loss: [1.3093754]; G_loss: [0.7097763]\n",
      "Iter-52000; D_loss: [1.2960666]; G_loss: [0.8609532]\n",
      "Iter-53000; D_loss: [1.2860411]; G_loss: [0.8167873]\n",
      "Iter-54000; D_loss: [1.1852896]; G_loss: [1.1119295]\n",
      "Iter-55000; D_loss: [1.2159462]; G_loss: [1.0462309]\n",
      "Iter-56000; D_loss: [1.165293]; G_loss: [1.0212245]\n",
      "Iter-57000; D_loss: [1.2709322]; G_loss: [0.95799506]\n",
      "Iter-58000; D_loss: [1.3368826]; G_loss: [1.0172586]\n",
      "Iter-59000; D_loss: [1.1215222]; G_loss: [1.0205284]\n",
      "Iter-60000; D_loss: [1.1468234]; G_loss: [0.86191404]\n",
      "Iter-61000; D_loss: [1.2284193]; G_loss: [0.7398978]\n",
      "Iter-62000; D_loss: [1.2647249]; G_loss: [0.86189073]\n",
      "Iter-63000; D_loss: [1.1450146]; G_loss: [0.9017384]\n",
      "Iter-64000; D_loss: [1.157279]; G_loss: [0.9415702]\n",
      "Iter-65000; D_loss: [1.1758933]; G_loss: [0.9779982]\n",
      "Iter-66000; D_loss: [1.3541293]; G_loss: [0.90469533]\n",
      "Iter-67000; D_loss: [1.1921546]; G_loss: [0.8745231]\n",
      "Iter-68000; D_loss: [1.2176751]; G_loss: [0.89110893]\n",
      "Iter-69000; D_loss: [1.2348335]; G_loss: [0.87384576]\n",
      "Iter-70000; D_loss: [1.0912578]; G_loss: [0.89435375]\n",
      "Iter-71000; D_loss: [1.1794899]; G_loss: [0.7988528]\n",
      "Iter-72000; D_loss: [1.0653758]; G_loss: [1.0169325]\n",
      "Iter-73000; D_loss: [1.0801299]; G_loss: [1.0017835]\n",
      "Iter-74000; D_loss: [1.2309161]; G_loss: [0.9414063]\n",
      "Iter-75000; D_loss: [1.1103532]; G_loss: [1.0957922]\n",
      "Iter-76000; D_loss: [1.1539538]; G_loss: [0.9919355]\n",
      "Iter-77000; D_loss: [1.1862975]; G_loss: [0.95225465]\n",
      "Iter-78000; D_loss: [1.0828183]; G_loss: [1.0079066]\n",
      "Iter-79000; D_loss: [1.0978984]; G_loss: [1.1636515]\n",
      "Iter-80000; D_loss: [1.1299002]; G_loss: [0.94272697]\n",
      "Iter-81000; D_loss: [1.1587158]; G_loss: [1.1644824]\n",
      "Iter-82000; D_loss: [1.047502]; G_loss: [1.0047666]\n",
      "Iter-83000; D_loss: [1.0710969]; G_loss: [1.0105566]\n",
      "Iter-84000; D_loss: [1.2215877]; G_loss: [0.9185116]\n",
      "Iter-85000; D_loss: [1.011039]; G_loss: [0.98608404]\n",
      "Iter-86000; D_loss: [1.1669626]; G_loss: [0.9524191]\n",
      "Iter-87000; D_loss: [1.0522966]; G_loss: [0.9290652]\n",
      "Iter-88000; D_loss: [1.1621134]; G_loss: [0.86394584]\n",
      "Iter-89000; D_loss: [1.2231708]; G_loss: [1.0743831]\n",
      "Iter-90000; D_loss: [1.1569246]; G_loss: [1.0131888]\n",
      "Iter-91000; D_loss: [1.1555223]; G_loss: [1.1052586]\n",
      "Iter-92000; D_loss: [1.0138388]; G_loss: [1.1214094]\n",
      "Iter-93000; D_loss: [1.1247103]; G_loss: [1.0132449]\n",
      "Iter-94000; D_loss: [0.9425658]; G_loss: [1.1925493]\n",
      "Iter-95000; D_loss: [1.0793226]; G_loss: [0.9731137]\n",
      "Iter-96000; D_loss: [0.99001944]; G_loss: [0.9196255]\n",
      "Iter-97000; D_loss: [0.9909556]; G_loss: [1.1497691]\n",
      "Iter-98000; D_loss: [1.1288877]; G_loss: [1.1963787]\n",
      "Iter-99000; D_loss: [1.0123545]; G_loss: [1.1686933]\n"
     ]
    }
   ],
   "source": [
    "for it in range(100000):\n",
    "    # Sample data\n",
    "    z = Variable(torch.randn(mb_size, Z_dim))\n",
    "#     X, _ = mnist.train.next_batch(mb_size)\n",
    "    X = next_batch(mb_size, X_train)\n",
    "    X = Variable(torch.from_numpy(X).float())\n",
    "\n",
    "    # Dicriminator forward-loss-backward-update\n",
    "    G_sample = G(z)\n",
    "    D_real = D(X)\n",
    "    D_fake = D(G_sample)\n",
    "\n",
    "    D_loss_real = nn.binary_cross_entropy(D_real, ones_label)\n",
    "    D_loss_fake = nn.binary_cross_entropy(D_fake, zeros_label)\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "    D_loss.backward()\n",
    "    D_solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Generator forward-loss-backward-update\n",
    "    z = Variable(torch.randn(mb_size, Z_dim))\n",
    "    G_sample = G(z)\n",
    "    D_fake = D(G_sample)\n",
    "\n",
    "    G_loss = nn.binary_cross_entropy(D_fake, ones_label)\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, D_loss.data.numpy(), G_loss.data.numpy()))\n",
    "\n",
    "        samples = G(z).data.numpy()[:16]\n",
    "\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        gs = gridspec.GridSpec(4, 4)\n",
    "        gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(sample.reshape(16, 4), cmap='Greys_r')\n",
    "\n",
    "        if not os.path.exists('out/'):\n",
    "            os.makedirs('out/')\n",
    "\n",
    "        plt.savefig('out/{}.png'.format(str(c).zfill(3)), bbox_inches='tight')\n",
    "        c += 1\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Variable(torch.from_numpy(X_test[:32]).float(), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[0].data.numpy().reshape((16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "myD = D(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.6570\n",
       " 0.3254\n",
       " 0.3938\n",
       " 0.1476\n",
       " 0.7991\n",
       " 0.7262\n",
       " 0.2260\n",
       " 0.5738\n",
       " 0.8807\n",
       " 0.6340\n",
       " 0.3272\n",
       " 0.2798\n",
       " 0.6505\n",
       " 0.3209\n",
       " 0.9394\n",
       " 0.4927\n",
       " 0.1952\n",
       " 0.0693\n",
       " 0.2091\n",
       " 0.3245\n",
       " 0.5301\n",
       " 0.3456\n",
       " 0.9675\n",
       " 0.3239\n",
       " 0.2765\n",
       " 0.4952\n",
       " 0.5312\n",
       " 0.4809\n",
       " 0.6414\n",
       " 0.7416\n",
       " 0.4703\n",
       " 0.4125\n",
       "[torch.FloatTensor of size 32x1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "myD.backward(ones_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.26253369e-02,  1.61539644e-01,  3.82690251e-01,\n",
       "         3.82950276e-01],\n",
       "       [-1.80268359e+00, -7.07610369e+00, -1.10227404e+01,\n",
       "        -3.33039308e+00],\n",
       "       [-4.70180847e-02, -3.64446253e-01, -2.50311941e-01,\n",
       "         6.85633481e-01],\n",
       "       [-1.15009390e-01, -3.49157870e-01, -1.31591940e+00,\n",
       "         2.71643847e-01],\n",
       "       [ 1.70627356e-01,  2.83755571e-01,  2.91358024e-01,\n",
       "         2.72754520e-01],\n",
       "       [-1.60105661e-01, -4.29261833e-01, -3.17726433e-01,\n",
       "        -1.93338469e-01],\n",
       "       [-1.08871513e+02, -3.79472656e+01, -8.99551697e+01,\n",
       "        -1.18808876e+02],\n",
       "       [-2.02404514e-01, -4.95498925e-01,  1.85605258e-01,\n",
       "        -4.98765260e-01],\n",
       "       [ 3.90781999e-01, -2.26147920e-01, -2.55456734e-02,\n",
       "        -2.13494718e-01],\n",
       "       [ 3.09839189e-01, -2.82146722e-01, -2.10579664e-01,\n",
       "        -1.99370444e-01],\n",
       "       [-2.96096146e-01, -1.39825881e-01, -1.86250731e-01,\n",
       "        -3.18873435e-01],\n",
       "       [-9.59123421e+00, -1.28624001e+01, -9.65364742e+00,\n",
       "        -9.63182068e+00],\n",
       "       [-8.97628721e-03,  2.92392343e-01,  2.65920579e-01,\n",
       "         2.24431455e-02],\n",
       "       [-7.45628998e-02,  8.54221582e-02, -3.63981217e-01,\n",
       "        -2.83494383e-01],\n",
       "       [ 1.61499783e-01, -1.04395607e-02, -8.07871819e-02,\n",
       "        -3.36547613e-01],\n",
       "       [-9.47393799e+00, -9.04061985e+00, -1.02343855e+01,\n",
       "        -1.05821285e+01]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.grad.data.numpy()[0].reshape((16,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs2 = inputs.data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.0413351e-01,  5.3565968e-02, -4.8952142e-04,  4.6540376e-02,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        2.4128921e-01,  4.8542872e-02,  5.9283283e-02,  4.6531204e-02,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        2.6197243e-01,  6.8191029e-02,  4.2327818e-01,  4.5908786e-02,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "        3.9717063e-01,  6.4666504e-01,  3.8751873e-01,  4.4254178e-01,\n",
       "        5.2033836e-01,  8.7208027e-01,  1.7182477e-02,  1.8739057e-01,\n",
       "        6.2334287e-01,  9.9110305e-01,  1.5720096e-01,  3.7421860e-02,\n",
       "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a448014a8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2586e748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(inputs2.reshape((16,4)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       " 0.6570\n",
       "[torch.FloatTensor of size 64x1]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D(Variable(torch.from_numpy(inputs2.flatten()).float(), requires_grad=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(G_params, open(\"data/gan/G_params.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(D_params, open(\"data/gan/D_params.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.start = datetime.now()\n",
    "lr = .8\n",
    "e = 0.1\n",
    "y = .95\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "for i in tqdm(range(self.num_episodes)):\n",
    "    #Reset environment and get first new observation\n",
    "    s = self.env.reset()\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    #The Q-Table learning algorithm\n",
    "    while j < 200:\n",
    "        j+=1\n",
    "        #Choose an action by greedily (with noise) picking from Q table\n",
    "        a = None\n",
    "        if random.uniform(0,1) < e:\n",
    "            a = self.env.action_space.sample()\n",
    "        else:\n",
    "            a = np.argmax(self.Q[s,:])\n",
    "        #Get new state and reward from environment\n",
    "        s1,r,d,_ = self.env.step(a)\n",
    "        if d == True and r != 1:\n",
    "            self.Q[s, a] -= 0.01\n",
    "        #Update Q-Table with new knowledge\n",
    "        self.Q[s,a] = self.Q[s,a] + lr*(r + y*np.max(self.Q[s1,:]) - self.Q[s,a])\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        if d == True and r > 0:\n",
    "            self.train_successes.append((i, j))\n",
    "        if d == True:\n",
    "            #Reduce chance of random action as we train the model.\n",
    "#             e = 1./((i/50) + 10)\n",
    "            break\n",
    "    rList.append(rAll)\n",
    "self.done = True\n",
    "self.end = datetime.now()\n",
    "self.score = sum(rList)/self.num_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gan)",
   "language": "python",
   "name": "gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
