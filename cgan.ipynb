{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting tmp/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting tmp/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting tmp/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting tmp/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gvsi/.virtualenvs/gan/lib/python3.6/site-packages/torch/nn/functional.py:767: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; D_loss: [ 1.33349252]; G_loss: [ 2.48869801]\n",
      "Iter-1000; D_loss: [ 0.00156199]; G_loss: [ 8.10518837]\n",
      "Iter-2000; D_loss: [ 0.01504124]; G_loss: [ 5.31819725]\n",
      "Iter-3000; D_loss: [ 0.03778245]; G_loss: [ 8.59025383]\n",
      "Iter-4000; D_loss: [ 0.21632931]; G_loss: [ 3.64234304]\n",
      "Iter-5000; D_loss: [ 0.22219378]; G_loss: [ 4.61682892]\n",
      "Iter-6000; D_loss: [ 0.46977144]; G_loss: [ 3.83009362]\n",
      "Iter-7000; D_loss: [ 0.73649943]; G_loss: [ 3.16015077]\n",
      "Iter-8000; D_loss: [ 0.33622453]; G_loss: [ 3.54452825]\n",
      "Iter-9000; D_loss: [ 0.56718612]; G_loss: [ 3.40774465]\n",
      "Iter-10000; D_loss: [ 0.80504495]; G_loss: [ 2.54718018]\n",
      "Iter-11000; D_loss: [ 0.68731451]; G_loss: [ 1.78875351]\n",
      "Iter-12000; D_loss: [ 0.75565088]; G_loss: [ 2.70864868]\n",
      "Iter-13000; D_loss: [ 0.73045748]; G_loss: [ 2.15528035]\n",
      "Iter-14000; D_loss: [ 0.70220411]; G_loss: [ 2.06548715]\n",
      "Iter-15000; D_loss: [ 0.98210537]; G_loss: [ 2.16292977]\n",
      "Iter-16000; D_loss: [ 0.68324411]; G_loss: [ 2.07659578]\n",
      "Iter-17000; D_loss: [ 0.77837914]; G_loss: [ 2.14624119]\n",
      "Iter-18000; D_loss: [ 0.89041853]; G_loss: [ 1.56250691]\n",
      "Iter-19000; D_loss: [ 0.75571811]; G_loss: [ 1.84993911]\n",
      "Iter-20000; D_loss: [ 0.81196165]; G_loss: [ 1.74640632]\n",
      "Iter-21000; D_loss: [ 0.88995087]; G_loss: [ 1.84061348]\n",
      "Iter-22000; D_loss: [ 0.71092737]; G_loss: [ 1.83868384]\n",
      "Iter-23000; D_loss: [ 1.04601538]; G_loss: [ 1.89922225]\n",
      "Iter-24000; D_loss: [ 0.92607427]; G_loss: [ 1.9557004]\n",
      "Iter-25000; D_loss: [ 0.77235734]; G_loss: [ 1.70808327]\n",
      "Iter-26000; D_loss: [ 0.7802273]; G_loss: [ 1.79094052]\n",
      "Iter-27000; D_loss: [ 0.76145327]; G_loss: [ 1.82806146]\n",
      "Iter-28000; D_loss: [ 0.77921367]; G_loss: [ 1.76928735]\n",
      "Iter-29000; D_loss: [ 0.81022787]; G_loss: [ 1.7852627]\n",
      "Iter-30000; D_loss: [ 0.93731809]; G_loss: [ 1.69269252]\n",
      "Iter-31000; D_loss: [ 0.94447422]; G_loss: [ 2.03801632]\n",
      "Iter-32000; D_loss: [ 0.85676771]; G_loss: [ 1.97351968]\n",
      "Iter-33000; D_loss: [ 0.99314559]; G_loss: [ 1.82897699]\n",
      "Iter-34000; D_loss: [ 0.76315081]; G_loss: [ 1.70635688]\n",
      "Iter-35000; D_loss: [ 0.99565899]; G_loss: [ 2.11812496]\n",
      "Iter-36000; D_loss: [ 0.93266165]; G_loss: [ 1.83133745]\n",
      "Iter-37000; D_loss: [ 0.93640846]; G_loss: [ 1.91489971]\n",
      "Iter-38000; D_loss: [ 0.68906957]; G_loss: [ 1.90828168]\n",
      "Iter-39000; D_loss: [ 0.85606945]; G_loss: [ 1.81793165]\n",
      "Iter-40000; D_loss: [ 0.90561861]; G_loss: [ 1.53128755]\n",
      "Iter-41000; D_loss: [ 0.88386571]; G_loss: [ 1.38545704]\n",
      "Iter-42000; D_loss: [ 0.87299204]; G_loss: [ 1.78344238]\n",
      "Iter-43000; D_loss: [ 0.79877484]; G_loss: [ 1.75306034]\n",
      "Iter-44000; D_loss: [ 0.86474454]; G_loss: [ 1.60555351]\n",
      "Iter-45000; D_loss: [ 0.84730047]; G_loss: [ 1.99092531]\n",
      "Iter-46000; D_loss: [ 0.57475197]; G_loss: [ 1.63054943]\n",
      "Iter-47000; D_loss: [ 0.72588658]; G_loss: [ 1.94884014]\n",
      "Iter-48000; D_loss: [ 0.88554204]; G_loss: [ 2.0186708]\n",
      "Iter-49000; D_loss: [ 0.87016857]; G_loss: [ 2.00163174]\n",
      "Iter-50000; D_loss: [ 0.91309965]; G_loss: [ 1.71537828]\n",
      "Iter-51000; D_loss: [ 0.78667766]; G_loss: [ 1.78937268]\n",
      "Iter-52000; D_loss: [ 0.99901134]; G_loss: [ 1.84977019]\n",
      "Iter-53000; D_loss: [ 0.81970757]; G_loss: [ 1.64106154]\n",
      "Iter-54000; D_loss: [ 0.78765327]; G_loss: [ 1.9921329]\n",
      "Iter-55000; D_loss: [ 0.66530204]; G_loss: [ 1.66406953]\n",
      "Iter-56000; D_loss: [ 0.68739951]; G_loss: [ 1.70244181]\n",
      "Iter-57000; D_loss: [ 0.81927609]; G_loss: [ 1.79770982]\n",
      "Iter-58000; D_loss: [ 0.76279777]; G_loss: [ 1.60049844]\n",
      "Iter-59000; D_loss: [ 0.90967476]; G_loss: [ 2.38130236]\n",
      "Iter-60000; D_loss: [ 0.7594285]; G_loss: [ 1.63903344]\n",
      "Iter-61000; D_loss: [ 0.82220632]; G_loss: [ 1.71589887]\n",
      "Iter-62000; D_loss: [ 0.71559262]; G_loss: [ 1.79037488]\n",
      "Iter-63000; D_loss: [ 0.68294293]; G_loss: [ 2.00751376]\n",
      "Iter-64000; D_loss: [ 1.01717949]; G_loss: [ 1.61980629]\n",
      "Iter-65000; D_loss: [ 0.82617891]; G_loss: [ 1.81117809]\n",
      "Iter-66000; D_loss: [ 0.78841364]; G_loss: [ 2.27550507]\n",
      "Iter-67000; D_loss: [ 0.7009728]; G_loss: [ 1.59697032]\n",
      "Iter-68000; D_loss: [ 0.86240923]; G_loss: [ 1.92809665]\n",
      "Iter-69000; D_loss: [ 0.9434244]; G_loss: [ 1.76168108]\n",
      "Iter-70000; D_loss: [ 0.81316429]; G_loss: [ 1.65701032]\n",
      "Iter-71000; D_loss: [ 0.75666165]; G_loss: [ 1.99120879]\n",
      "Iter-72000; D_loss: [ 1.2361002]; G_loss: [ 1.77342403]\n",
      "Iter-73000; D_loss: [ 0.65245241]; G_loss: [ 1.62017012]\n",
      "Iter-74000; D_loss: [ 0.87781858]; G_loss: [ 1.99994826]\n",
      "Iter-75000; D_loss: [ 0.85993016]; G_loss: [ 1.63033617]\n",
      "Iter-76000; D_loss: [ 0.80886853]; G_loss: [ 1.72717869]\n",
      "Iter-77000; D_loss: [ 0.98067927]; G_loss: [ 1.97965646]\n",
      "Iter-78000; D_loss: [ 0.82020921]; G_loss: [ 1.67240179]\n",
      "Iter-79000; D_loss: [ 0.92394775]; G_loss: [ 1.7350657]\n",
      "Iter-80000; D_loss: [ 0.80613089]; G_loss: [ 1.60302722]\n",
      "Iter-81000; D_loss: [ 0.72869289]; G_loss: [ 1.79734266]\n",
      "Iter-82000; D_loss: [ 0.88693225]; G_loss: [ 1.68059707]\n",
      "Iter-83000; D_loss: [ 1.00153828]; G_loss: [ 1.87177312]\n",
      "Iter-84000; D_loss: [ 0.68539834]; G_loss: [ 1.81256485]\n",
      "Iter-85000; D_loss: [ 0.70841831]; G_loss: [ 1.93063784]\n",
      "Iter-86000; D_loss: [ 0.82989198]; G_loss: [ 2.11608148]\n",
      "Iter-87000; D_loss: [ 0.82896376]; G_loss: [ 1.98507226]\n",
      "Iter-88000; D_loss: [ 0.9143014]; G_loss: [ 2.17620134]\n",
      "Iter-89000; D_loss: [ 0.86229706]; G_loss: [ 1.68574166]\n",
      "Iter-90000; D_loss: [ 0.86599952]; G_loss: [ 1.93478453]\n",
      "Iter-91000; D_loss: [ 0.92059493]; G_loss: [ 1.53787899]\n",
      "Iter-92000; D_loss: [ 0.98767149]; G_loss: [ 1.58263493]\n",
      "Iter-93000; D_loss: [ 0.84078622]; G_loss: [ 1.92468512]\n",
      "Iter-94000; D_loss: [ 0.71039742]; G_loss: [ 1.80180037]\n",
      "Iter-95000; D_loss: [ 0.73774374]; G_loss: [ 1.7769922]\n",
      "Iter-96000; D_loss: [ 0.71584755]; G_loss: [ 1.37550318]\n",
      "Iter-97000; D_loss: [ 0.80326807]; G_loss: [ 1.65525973]\n",
      "Iter-98000; D_loss: [ 0.8225612]; G_loss: [ 1.90510619]\n",
      "Iter-99000; D_loss: [ 0.98989749]; G_loss: [ 1.80887628]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets('tmp/MNIST_data', one_hot=True)\n",
    "mb_size = 64\n",
    "Z_dim = 100\n",
    "X_dim = mnist.train.images.shape[1]\n",
    "y_dim = mnist.train.labels.shape[1]\n",
    "h_dim = 128\n",
    "cnt = 0\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return Variable(torch.randn(*size) * xavier_stddev, requires_grad=True)\n",
    "\n",
    "\n",
    "\"\"\" ==================== GENERATOR ======================== \"\"\"\n",
    "\n",
    "Wzh = xavier_init(size=[Z_dim + y_dim, h_dim])\n",
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whx = xavier_init(size=[h_dim, X_dim])\n",
    "bhx = Variable(torch.zeros(X_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def G(z, c):\n",
    "    inputs = torch.cat([z, c], 1)\n",
    "    h = nn.relu(inputs @ Wzh + bzh.repeat(inputs.size(0), 1))\n",
    "    X = nn.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
    "    return X\n",
    "\n",
    "\n",
    "\"\"\" ==================== DISCRIMINATOR ======================== \"\"\"\n",
    "\n",
    "Wxh = xavier_init(size=[X_dim + y_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Why = xavier_init(size=[h_dim, 1])\n",
    "bhy = Variable(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "\n",
    "def D(X, c):\n",
    "    inputs = torch.cat([X, c], 1)\n",
    "    h = nn.relu(inputs @ Wxh + bxh.repeat(inputs.size(0), 1))\n",
    "    y = nn.sigmoid(h @ Why + bhy.repeat(h.size(0), 1))\n",
    "    return y\n",
    "\n",
    "\n",
    "G_params = [Wzh, bzh, Whx, bhx]\n",
    "D_params = [Wxh, bxh, Why, bhy]\n",
    "params = G_params + D_params\n",
    "\n",
    "\n",
    "\"\"\" ===================== TRAINING ======================== \"\"\"\n",
    "\n",
    "\n",
    "def reset_grad():\n",
    "    for p in params:\n",
    "        if p.grad is not None:\n",
    "            data = p.grad.data\n",
    "            p.grad = Variable(data.new().resize_as_(data).zero_())\n",
    "\n",
    "\n",
    "G_solver = optim.Adam(G_params, lr=1e-3)\n",
    "D_solver = optim.Adam(D_params, lr=1e-3)\n",
    "\n",
    "ones_label = Variable(torch.ones(mb_size))\n",
    "zeros_label = Variable(torch.zeros(mb_size))\n",
    "\n",
    "\n",
    "for it in range(100000):\n",
    "    # Sample data\n",
    "    z = Variable(torch.randn(mb_size, Z_dim))\n",
    "    X, c = mnist.train.next_batch(mb_size)\n",
    "    X = Variable(torch.from_numpy(X))\n",
    "    c = Variable(torch.from_numpy(c.astype('float32')))\n",
    "\n",
    "    # Dicriminator forward-loss-backward-update\n",
    "    G_sample = G(z, c)\n",
    "    D_real = D(X, c)\n",
    "    D_fake = D(G_sample, c)\n",
    "\n",
    "    D_loss_real = nn.binary_cross_entropy(D_real, ones_label)\n",
    "    D_loss_fake = nn.binary_cross_entropy(D_fake, zeros_label)\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "    D_loss.backward()\n",
    "    D_solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Generator forward-loss-backward-update\n",
    "    z = Variable(torch.randn(mb_size, Z_dim))\n",
    "    G_sample = G(z, c)\n",
    "    D_fake = D(G_sample, c)\n",
    "\n",
    "    G_loss = nn.binary_cross_entropy(D_fake, ones_label)\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, D_loss.data.numpy(), G_loss.data.numpy()))\n",
    "\n",
    "        c = np.zeros(shape=[mb_size, y_dim], dtype='float32')\n",
    "        c[:, np.random.randint(0, 10)] = 1.\n",
    "        c = Variable(torch.from_numpy(c))\n",
    "        samples = G(z, c).data.numpy()[:16]\n",
    "\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        gs = gridspec.GridSpec(4, 4)\n",
    "        gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "        if not os.path.exists('out/'):\n",
    "            os.makedirs('out/')\n",
    "\n",
    "        plt.savefig('out/{}.png'.format(str(cnt).zfill(3)), bbox_inches='tight')\n",
    "        cnt += 1\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-af04d225c5c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "c = np.zeros(shape=[mb_size, y_dim], dtype='float32')\n",
    "c[:, 7] = 1.\n",
    "c = Variable(torch.from_numpy(c))\n",
    "print(c)\n",
    "samples = G(z, c).data.numpy()[:16]\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "gs = gridspec.GridSpec(4, 4)\n",
    "gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    plt.axis('off')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_aspect('equal')\n",
    "    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
