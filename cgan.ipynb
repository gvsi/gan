{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting tmp/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting tmp/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting tmp/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting tmp/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gvsi/.virtualenvs/gan/lib/python3.6/site-packages/torch/nn/functional.py:767: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; D_loss: [ 1.33349252]; G_loss: [ 2.48869801]\n",
      "Iter-1000; D_loss: [ 0.00156199]; G_loss: [ 8.10518837]\n",
      "Iter-2000; D_loss: [ 0.01504124]; G_loss: [ 5.31819725]\n",
      "Iter-3000; D_loss: [ 0.03778245]; G_loss: [ 8.59025383]\n",
      "Iter-4000; D_loss: [ 0.21632931]; G_loss: [ 3.64234304]\n",
      "Iter-5000; D_loss: [ 0.22219378]; G_loss: [ 4.61682892]\n",
      "Iter-6000; D_loss: [ 0.46977144]; G_loss: [ 3.83009362]\n",
      "Iter-7000; D_loss: [ 0.73649943]; G_loss: [ 3.16015077]\n",
      "Iter-8000; D_loss: [ 0.33622453]; G_loss: [ 3.54452825]\n",
      "Iter-9000; D_loss: [ 0.56718612]; G_loss: [ 3.40774465]\n",
      "Iter-10000; D_loss: [ 0.80504495]; G_loss: [ 2.54718018]\n",
      "Iter-11000; D_loss: [ 0.68731451]; G_loss: [ 1.78875351]\n",
      "Iter-12000; D_loss: [ 0.75565088]; G_loss: [ 2.70864868]\n",
      "Iter-13000; D_loss: [ 0.73045748]; G_loss: [ 2.15528035]\n",
      "Iter-14000; D_loss: [ 0.70220411]; G_loss: [ 2.06548715]\n",
      "Iter-15000; D_loss: [ 0.98210537]; G_loss: [ 2.16292977]\n",
      "Iter-16000; D_loss: [ 0.68324411]; G_loss: [ 2.07659578]\n",
      "Iter-17000; D_loss: [ 0.77837914]; G_loss: [ 2.14624119]\n",
      "Iter-18000; D_loss: [ 0.89041853]; G_loss: [ 1.56250691]\n",
      "Iter-19000; D_loss: [ 0.75571811]; G_loss: [ 1.84993911]\n",
      "Iter-20000; D_loss: [ 0.81196165]; G_loss: [ 1.74640632]\n",
      "Iter-21000; D_loss: [ 0.88995087]; G_loss: [ 1.84061348]\n",
      "Iter-22000; D_loss: [ 0.71092737]; G_loss: [ 1.83868384]\n",
      "Iter-23000; D_loss: [ 1.04601538]; G_loss: [ 1.89922225]\n",
      "Iter-24000; D_loss: [ 0.92607427]; G_loss: [ 1.9557004]\n",
      "Iter-25000; D_loss: [ 0.77235734]; G_loss: [ 1.70808327]\n",
      "Iter-26000; D_loss: [ 0.7802273]; G_loss: [ 1.79094052]\n",
      "Iter-27000; D_loss: [ 0.76145327]; G_loss: [ 1.82806146]\n",
      "Iter-28000; D_loss: [ 0.77921367]; G_loss: [ 1.76928735]\n",
      "Iter-29000; D_loss: [ 0.81022787]; G_loss: [ 1.7852627]\n",
      "Iter-30000; D_loss: [ 0.93731809]; G_loss: [ 1.69269252]\n",
      "Iter-31000; D_loss: [ 0.94447422]; G_loss: [ 2.03801632]\n",
      "Iter-32000; D_loss: [ 0.85676771]; G_loss: [ 1.97351968]\n",
      "Iter-33000; D_loss: [ 0.99314559]; G_loss: [ 1.82897699]\n",
      "Iter-34000; D_loss: [ 0.76315081]; G_loss: [ 1.70635688]\n",
      "Iter-35000; D_loss: [ 0.99565899]; G_loss: [ 2.11812496]\n",
      "Iter-36000; D_loss: [ 0.93266165]; G_loss: [ 1.83133745]\n",
      "Iter-37000; D_loss: [ 0.93640846]; G_loss: [ 1.91489971]\n",
      "Iter-38000; D_loss: [ 0.68906957]; G_loss: [ 1.90828168]\n",
      "Iter-39000; D_loss: [ 0.85606945]; G_loss: [ 1.81793165]\n",
      "Iter-40000; D_loss: [ 0.90561861]; G_loss: [ 1.53128755]\n",
      "Iter-41000; D_loss: [ 0.88386571]; G_loss: [ 1.38545704]\n",
      "Iter-42000; D_loss: [ 0.87299204]; G_loss: [ 1.78344238]\n",
      "Iter-43000; D_loss: [ 0.79877484]; G_loss: [ 1.75306034]\n",
      "Iter-44000; D_loss: [ 0.86474454]; G_loss: [ 1.60555351]\n",
      "Iter-45000; D_loss: [ 0.84730047]; G_loss: [ 1.99092531]\n",
      "Iter-46000; D_loss: [ 0.57475197]; G_loss: [ 1.63054943]\n",
      "Iter-47000; D_loss: [ 0.72588658]; G_loss: [ 1.94884014]\n",
      "Iter-48000; D_loss: [ 0.88554204]; G_loss: [ 2.0186708]\n",
      "Iter-49000; D_loss: [ 0.87016857]; G_loss: [ 2.00163174]\n",
      "Iter-50000; D_loss: [ 0.91309965]; G_loss: [ 1.71537828]\n",
      "Iter-51000; D_loss: [ 0.78667766]; G_loss: [ 1.78937268]\n",
      "Iter-52000; D_loss: [ 0.99901134]; G_loss: [ 1.84977019]\n",
      "Iter-53000; D_loss: [ 0.81970757]; G_loss: [ 1.64106154]\n",
      "Iter-54000; D_loss: [ 0.78765327]; G_loss: [ 1.9921329]\n",
      "Iter-55000; D_loss: [ 0.66530204]; G_loss: [ 1.66406953]\n",
      "Iter-56000; D_loss: [ 0.68739951]; G_loss: [ 1.70244181]\n",
      "Iter-57000; D_loss: [ 0.81927609]; G_loss: [ 1.79770982]\n",
      "Iter-58000; D_loss: [ 0.76279777]; G_loss: [ 1.60049844]\n",
      "Iter-59000; D_loss: [ 0.90967476]; G_loss: [ 2.38130236]\n",
      "Iter-60000; D_loss: [ 0.7594285]; G_loss: [ 1.63903344]\n",
      "Iter-61000; D_loss: [ 0.82220632]; G_loss: [ 1.71589887]\n",
      "Iter-62000; D_loss: [ 0.71559262]; G_loss: [ 1.79037488]\n",
      "Iter-63000; D_loss: [ 0.68294293]; G_loss: [ 2.00751376]\n",
      "Iter-64000; D_loss: [ 1.01717949]; G_loss: [ 1.61980629]\n",
      "Iter-65000; D_loss: [ 0.82617891]; G_loss: [ 1.81117809]\n",
      "Iter-66000; D_loss: [ 0.78841364]; G_loss: [ 2.27550507]\n",
      "Iter-67000; D_loss: [ 0.7009728]; G_loss: [ 1.59697032]\n",
      "Iter-68000; D_loss: [ 0.86240923]; G_loss: [ 1.92809665]\n",
      "Iter-69000; D_loss: [ 0.9434244]; G_loss: [ 1.76168108]\n",
      "Iter-70000; D_loss: [ 0.81316429]; G_loss: [ 1.65701032]\n",
      "Iter-71000; D_loss: [ 0.75666165]; G_loss: [ 1.99120879]\n",
      "Iter-72000; D_loss: [ 1.2361002]; G_loss: [ 1.77342403]\n",
      "Iter-73000; D_loss: [ 0.65245241]; G_loss: [ 1.62017012]\n",
      "Iter-74000; D_loss: [ 0.87781858]; G_loss: [ 1.99994826]\n",
      "Iter-75000; D_loss: [ 0.85993016]; G_loss: [ 1.63033617]\n",
      "Iter-76000; D_loss: [ 0.80886853]; G_loss: [ 1.72717869]\n",
      "Iter-77000; D_loss: [ 0.98067927]; G_loss: [ 1.97965646]\n",
      "Iter-78000; D_loss: [ 0.82020921]; G_loss: [ 1.67240179]\n",
      "Iter-79000; D_loss: [ 0.92394775]; G_loss: [ 1.7350657]\n",
      "Iter-80000; D_loss: [ 0.80613089]; G_loss: [ 1.60302722]\n",
      "Iter-81000; D_loss: [ 0.72869289]; G_loss: [ 1.79734266]\n",
      "Iter-82000; D_loss: [ 0.88693225]; G_loss: [ 1.68059707]\n",
      "Iter-83000; D_loss: [ 1.00153828]; G_loss: [ 1.87177312]\n",
      "Iter-84000; D_loss: [ 0.68539834]; G_loss: [ 1.81256485]\n",
      "Iter-85000; D_loss: [ 0.70841831]; G_loss: [ 1.93063784]\n",
      "Iter-86000; D_loss: [ 0.82989198]; G_loss: [ 2.11608148]\n",
      "Iter-87000; D_loss: [ 0.82896376]; G_loss: [ 1.98507226]\n",
      "Iter-88000; D_loss: [ 0.9143014]; G_loss: [ 2.17620134]\n",
      "Iter-89000; D_loss: [ 0.86229706]; G_loss: [ 1.68574166]\n",
      "Iter-90000; D_loss: [ 0.86599952]; G_loss: [ 1.93478453]\n",
      "Iter-91000; D_loss: [ 0.92059493]; G_loss: [ 1.53787899]\n",
      "Iter-92000; D_loss: [ 0.98767149]; G_loss: [ 1.58263493]\n",
      "Iter-93000; D_loss: [ 0.84078622]; G_loss: [ 1.92468512]\n",
      "Iter-94000; D_loss: [ 0.71039742]; G_loss: [ 1.80180037]\n",
      "Iter-95000; D_loss: [ 0.73774374]; G_loss: [ 1.7769922]\n",
      "Iter-96000; D_loss: [ 0.71584755]; G_loss: [ 1.37550318]\n",
      "Iter-97000; D_loss: [ 0.80326807]; G_loss: [ 1.65525973]\n",
      "Iter-98000; D_loss: [ 0.8225612]; G_loss: [ 1.90510619]\n",
      "Iter-99000; D_loss: [ 0.98989749]; G_loss: [ 1.80887628]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets('tmp/MNIST_data', one_hot=True)\n",
    "mb_size = 64\n",
    "Z_dim = 100\n",
    "X_dim = mnist.train.images.shape[1]\n",
    "y_dim = mnist.train.labels.shape[1]\n",
    "h_dim = 128\n",
    "cnt = 0\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return Variable(torch.randn(*size) * xavier_stddev, requires_grad=True)\n",
    "\n",
    "\n",
    "\"\"\" ==================== GENERATOR ======================== \"\"\"\n",
    "\n",
    "Wzh = xavier_init(size=[Z_dim + y_dim, h_dim])\n",
    "bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whx = xavier_init(size=[h_dim, X_dim])\n",
    "bhx = Variable(torch.zeros(X_dim), requires_grad=True)\n",
    "\n",
    "\n",
    "def G(z, c):\n",
    "    inputs = torch.cat([z, c], 1)\n",
    "    h = nn.relu(inputs @ Wzh + bzh.repeat(inputs.size(0), 1))\n",
    "    X = nn.sigmoid(h @ Whx + bhx.repeat(h.size(0), 1))\n",
    "    return X\n",
    "\n",
    "\n",
    "\"\"\" ==================== DISCRIMINATOR ======================== \"\"\"\n",
    "\n",
    "Wxh = xavier_init(size=[X_dim + y_dim, h_dim])\n",
    "bxh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Why = xavier_init(size=[h_dim, 1])\n",
    "bhy = Variable(torch.zeros(1), requires_grad=True)\n",
    "\n",
    "\n",
    "def D(X, c):\n",
    "    inputs = torch.cat([X, c], 1)\n",
    "    h = nn.relu(inputs @ Wxh + bxh.repeat(inputs.size(0), 1))\n",
    "    y = nn.sigmoid(h @ Why + bhy.repeat(h.size(0), 1))\n",
    "    return y\n",
    "\n",
    "\n",
    "G_params = [Wzh, bzh, Whx, bhx]\n",
    "D_params = [Wxh, bxh, Why, bhy]\n",
    "params = G_params + D_params\n",
    "\n",
    "\n",
    "\"\"\" ===================== TRAINING ======================== \"\"\"\n",
    "\n",
    "\n",
    "def reset_grad():\n",
    "    for p in params:\n",
    "        if p.grad is not None:\n",
    "            data = p.grad.data\n",
    "            p.grad = Variable(data.new().resize_as_(data).zero_())\n",
    "\n",
    "\n",
    "G_solver = optim.Adam(G_params, lr=1e-3)\n",
    "D_solver = optim.Adam(D_params, lr=1e-3)\n",
    "\n",
    "ones_label = Variable(torch.ones(mb_size))\n",
    "zeros_label = Variable(torch.zeros(mb_size))\n",
    "\n",
    "\n",
    "for it in range(100000):\n",
    "    # Sample data\n",
    "    z = Variable(torch.randn(mb_size, Z_dim))\n",
    "    X, c = mnist.train.next_batch(mb_size)\n",
    "    X = Variable(torch.from_numpy(X))\n",
    "    c = Variable(torch.from_numpy(c.astype('float32')))\n",
    "\n",
    "    # Dicriminator forward-loss-backward-update\n",
    "    G_sample = G(z, c)\n",
    "    D_real = D(X, c)\n",
    "    D_fake = D(G_sample, c)\n",
    "\n",
    "    D_loss_real = nn.binary_cross_entropy(D_real, ones_label)\n",
    "    D_loss_fake = nn.binary_cross_entropy(D_fake, zeros_label)\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "    D_loss.backward()\n",
    "    D_solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Generator forward-loss-backward-update\n",
    "    z = Variable(torch.randn(mb_size, Z_dim))\n",
    "    G_sample = G(z, c)\n",
    "    D_fake = D(G_sample, c)\n",
    "\n",
    "    G_loss = nn.binary_cross_entropy(D_fake, ones_label)\n",
    "\n",
    "    G_loss.backward()\n",
    "    G_solver.step()\n",
    "\n",
    "    # Housekeeping - reset gradient\n",
    "    reset_grad()\n",
    "\n",
    "    # Print and plot every now and then\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter-{}; D_loss: {}; G_loss: {}'.format(it, D_loss.data.numpy(), G_loss.data.numpy()))\n",
    "\n",
    "        c = np.zeros(shape=[mb_size, y_dim], dtype='float32')\n",
    "        c[:, np.random.randint(0, 10)] = 1.\n",
    "        c = Variable(torch.from_numpy(c))\n",
    "        samples = G(z, c).data.numpy()[:16]\n",
    "\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "        gs = gridspec.GridSpec(4, 4)\n",
    "        gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "        for i, sample in enumerate(samples):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            plt.axis('off')\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_aspect('equal')\n",
    "            plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "        if not os.path.exists('out/'):\n",
    "            os.makedirs('out/')\n",
    "\n",
    "        plt.savefig('out/{}.png'.format(str(cnt).zfill(3)), bbox_inches='tight')\n",
    "        cnt += 1\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "[torch.FloatTensor of size 64x10]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPMAAADuCAYAAADsvjF6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12865dfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "c = np.zeros(shape=[mb_size, y_dim], dtype='float32')\n",
    "c[:, 7] = 1.\n",
    "c = Variable(torch.from_numpy(c))\n",
    "print(c)\n",
    "samples = G(z, c).data.numpy()[:16]\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "gs = gridspec.GridSpec(4, 4)\n",
    "gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    plt.axis('off')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_aspect('equal')\n",
    "    plt.imshow(sample.reshape(28, 28), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
